{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6506b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "import pronouncing\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import json\n",
    "import boto3\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16dfabc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed C74amJRp730__chunk__48-10.mp4\n",
      "Removed C74amJRp730__chunk__48-0.mp4\n",
      "Removed C74amJRp730__video__22-4.mp4\n",
      "Removed C74amJRp730__chunk__48-1.mp4\n",
      "Removed C74amJRp730__chunk__48-11.mp4\n",
      "Removed C74amJRp730__video__3.mp4\n",
      "Removed C74amJRp730__chunk__48-13.mp4\n",
      "Removed C74amJRp730__chunk__48-3.mp4\n",
      "Removed C74amJRp730__text__43-1.json\n",
      "Removed C74amJRp730__video__19-1.mp4\n",
      "Removed C74amJRp730__chunk__48-2.mp4\n",
      "Removed C74amJRp730__chunk__48-12.mp4\n",
      "Removed C74amJRp730__video__9-6.mp4\n",
      "Removed C74amJRp730__chunk__48-16.mp4\n",
      "Removed C74amJRp730__chunk__48-6.mp4\n",
      "Removed C74amJRp730__chunk__48-7.mp4\n",
      "Removed C74amJRp730__chunk__48-17.mp4\n",
      "Removed C74amJRp730__chunk__48-29.mp4\n",
      "Removed C74amJRp730__chunk__48-15.mp4\n",
      "Removed C74amJRp730__chunk__48-5.mp4\n",
      "Removed C74amJRp730__video__43-1.mp4\n",
      "Removed C74amJRp730__chunk__48-4.mp4\n",
      "Removed C74amJRp730__chunk__48-14.mp4\n",
      "Removed C74amJRp730__chunk__48-28.mp4\n",
      "Removed C74amJRp730__video__6.mp4\n",
      "Removed C74amJRp730__chunk__49-3.mp4\n",
      "Removed C74amJRp730__chunk__49-2.mp4\n",
      "Removed C74amJRp730__chunk__49-0.mp4\n",
      "Removed C74amJRp730__chunk__49-1.mp4\n",
      "Removed C74amJRp730__chunk__49-5.mp4\n",
      "Removed C74amJRp730__chunk__47-18.mp4\n",
      "Removed C74amJRp730__chunk__49-4.mp4\n",
      "Removed C74amJRp730__chunk__49-6.mp4\n",
      "Removed C74amJRp730__chunk__47-9.mp4\n",
      "Removed C74amJRp730__chunk__47-8.mp4\n",
      "Removed C74amJRp730__chunk__49-7.mp4\n",
      "Removed C74amJRp730__video__27-6.mp4\n",
      "Removed C74amJRp730__video__28-13.mp4\n",
      "Removed C74amJRp730__video__34-1.mp4\n",
      "Removed C74amJRp730__chunk__47-17.mp4\n",
      "Removed C74amJRp730__chunk__47-5.mp4\n",
      "Removed C74amJRp730__chunk__47-4.mp4\n",
      "Removed C74amJRp730__chunk__47-16.mp4\n",
      "Removed C74amJRp730__chunk__43-2.mp4\n",
      "Removed C74amJRp730__chunk__49-9.mp4\n",
      "Removed C74amJRp730__chunk__47-14.mp4\n",
      "Removed C74amJRp730__chunk__47-6.mp4\n",
      "Removed C74amJRp730__chunk__49-10.mp4\n",
      "Removed C74amJRp730__video__23-15.mp4\n",
      "Removed C74amJRp730__chunk__47-7.mp4\n",
      "Removed C74amJRp730__chunk__47-15.mp4\n",
      "Removed C74amJRp730__chunk__49-8.mp4\n",
      "Removed C74amJRp730__chunk__43-3.mp4\n",
      "Removed C74amJRp730__chunk__47-3.mp4\n",
      "Removed C74amJRp730__video__25.mp4\n",
      "Removed C74amJRp730__video__31.mp4\n",
      "Removed C74amJRp730__chunk__47-11.mp4\n",
      "Removed C74amJRp730__chunk__45-1.mp4\n",
      "Removed C74amJRp730__chunk__45-0.mp4\n",
      "Removed C74amJRp730__chunk__47-10.mp4\n",
      "Removed C74amJRp730__chunk__47-2.mp4\n",
      "Removed C74amJRp730__video__12-5.mp4\n",
      "Removed C74amJRp730__chunk__43-6.mp4\n",
      "Removed C74amJRp730__video__30-0.mp4\n",
      "Removed C74amJRp730__chunk__43-4.mp4\n",
      "Removed C74amJRp730__chunk__47-0.mp4\n",
      "Removed C74amJRp730__chunk__47-12.mp4\n",
      "Removed C74amJRp730__chunk__45-2.mp4\n",
      "Removed C74amJRp730__chunk__47-13.mp4\n",
      "Removed C74amJRp730__chunk__47-1.mp4\n",
      "Removed C74amJRp730__chunk__43-5.mp4\n",
      "Removed C74amJRp730__video__30-1.mp4\n",
      "Removed C74amJRp730__chunk__48-25.mp4\n",
      "Removed C74amJRp730__chunk__48-31.mp4\n",
      "Removed C74amJRp730__chunk__44-4.mp4\n",
      "Removed C74amJRp730__chunk__48-19.mp4\n",
      "Removed C74amJRp730__chunk__48-9.mp4\n",
      "Removed C74amJRp730__video__40.mp4\n",
      "Removed C74amJRp730__video__39-11.mp4\n",
      "Removed C74amJRp730__chunk__48-8.mp4\n",
      "Removed C74amJRp730__chunk__44-5.mp4\n",
      "Removed C74amJRp730__chunk__48-18.mp4\n",
      "Removed C74amJRp730__chunk__48-30.mp4\n",
      "Removed C74amJRp730__chunk__48-24.mp4\n",
      "Removed C74amJRp730__video__8.mp4\n",
      "Removed C74amJRp730__chunk__48-32.mp4\n",
      "Removed C74amJRp730__chunk__48-26.mp4\n",
      "Removed C74amJRp730__video__13-17.mp4\n",
      "Removed C74amJRp730__chunk__48-27.mp4\n",
      "Removed C74amJRp730__chunk__48-33.mp4\n",
      "Removed C74amJRp730__chunk__44-2.mp4\n",
      "Removed C74amJRp730__chunk__48-23.mp4\n",
      "Removed C74amJRp730__chunk__46-0.mp4\n",
      "Removed C74amJRp730__chunk__46-1.mp4\n",
      "Removed C74amJRp730__chunk__48-22.mp4\n",
      "Removed C74amJRp730__chunk__44-3.mp4\n",
      "Removed C74amJRp730__video__11-4.mp4\n",
      "Removed C74amJRp730__chunk__44-1.mp4\n",
      "Removed C74amJRp730__chunk__48-20.mp4\n",
      "Removed C74amJRp730__chunk__48-34.mp4\n",
      "Removed C74amJRp730__chunk__48-35.mp4\n",
      "Removed C74amJRp730__chunk__48-21.mp4\n",
      "Removed C74amJRp730__chunk__44-0.mp4\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('.'):\n",
    "    if file.endswith('.mp4'):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed {file}\")\n",
    "    if file.endswith('.json'):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed {file}\")\n",
    "    if file.endswith('.npz'):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed {file}\")\n",
    "    if file.endswith('.mp3'):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2af064",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name = \"youtube\"\n",
    "region_name = \"us-east-1\"\n",
    "\n",
    "# Create a Secrets Manager client\n",
    "session = boto3.session.Session()\n",
    "secretsmanager = session.client(service_name='secretsmanager', region_name=region_name)\n",
    "\n",
    "get_secret_value_response = secretsmanager.get_secret_value(SecretId=secret_name)\n",
    "\n",
    "secret = get_secret_value_response['SecretString']\n",
    "api_key = json.loads(secret)[\"API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b50eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket = 'slip-ml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c2a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "torch_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550bcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True)\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20321e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c779ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_videos(playlist_url):\n",
    "    \"\"\"\n",
    "    Extract all video URLs from a YouTube playlist using the YouTube Data API.\n",
    "    \n",
    "    Args:\n",
    "        playlist_url (str): The YouTube playlist URL (e.g., https://www.youtube.com/playlist?list=PL86SiVwkw_odmp-RVzD8yef3wU7Z2uD5a)\n",
    "        api_key (str): Your YouTube Data API key\n",
    "    \n",
    "    Returns:\n",
    "        list: List of video URLs\n",
    "    \"\"\"\n",
    "    # Extract playlist ID from URL\n",
    "    playlist_id = playlist_url.split(\"list=\")[-1].split(\"&\")[0]\n",
    "    \n",
    "    # Initialize YouTube API client\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    video_urls = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Request playlist items\n",
    "            request = youtube.playlistItems().list(\n",
    "                part=\"contentDetails\",\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,  # Max allowed per request\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            # Extract video IDs and create URLs\n",
    "            for item in response['items']:\n",
    "                video_id = item['contentDetails']['videoId']\n",
    "                video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "                video_urls.append(video_url)\n",
    "            \n",
    "            # Check for next page\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "    \n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e2fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(local_file, s3_folder):\n",
    "    s3_file = f\"{s3_folder}/{local_file}\"\n",
    "    try:\n",
    "        s3_client.upload_file(local_file, bucket, s3_file)\n",
    "        print(f\"Upload Successful: {local_file} -> {s3_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file was not found: {local_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7f58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video_yt_dlp(url):\n",
    "    # extract video ID from the URL\n",
    "    video_id = url.split(\"v=\")[-1]\n",
    "    if \"&\" in video_id:\n",
    "        video_id = video_id.split(\"&\")[0]\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": f\"{video_id}.%(ext)s\",  # Output path and filename\n",
    "        \"format\": \"best\",  # Select the best single file (video + audio)\n",
    "        \"merge_output_format\": None,  # Avoid merging, stick to single stream\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(\"Download completed successfully!\")\n",
    "        upload_to_s3(video_id + '.mp4', 'data/ted')\n",
    "        return video_id\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f24746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_intervals(video_id):\n",
    "    \"\"\"\n",
    "    Detects intervals in a video where a face is present, with a 1-second buffer for ending intervals.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with 'start' and 'end' times for each interval where a face is detected.\n",
    "    \"\"\"\n",
    "    face_intervals = []\n",
    "    try:\n",
    "        # Initialize MediaPipe Face Detection\n",
    "        mp_face_detection = mp.solutions.face_detection\n",
    "        face_detection = mp_face_detection.FaceDetection()\n",
    "\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_id + '.mp4')\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "        frame_duration = 1 / fps  # Duration of each frame in seconds\n",
    "\n",
    "        face_present = False\n",
    "        start_time = None\n",
    "        no_face_frames = 0  # Counter for frames without a face\n",
    "\n",
    "        frame_index = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to RGB for MediaPipe\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(rgb_frame)\n",
    "\n",
    "            # Check if a face is detected\n",
    "            if results.detections:\n",
    "                if not face_present:\n",
    "                    # Start a new interval\n",
    "                    start_time = frame_index * frame_duration\n",
    "                    face_present = True\n",
    "                no_face_frames = 0  # Reset no-face counter\n",
    "            else:\n",
    "                if face_present:\n",
    "                    no_face_frames += 1\n",
    "                    # If no face is detected for 1 second, end the interval\n",
    "                    if no_face_frames >= fps*1.5:\n",
    "                        end_time = frame_index * frame_duration\n",
    "                        face_intervals.append({\"start\": start_time, \"end\": end_time})\n",
    "                        face_present = False\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "        # Handle the case where the video ends while a face is still present\n",
    "        if face_present:\n",
    "            end_time = frame_index * frame_duration\n",
    "            face_intervals.append({\"start\": start_time, \"end\": end_time})\n",
    "\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during face detection: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return face_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ef57e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_video(video_id, face_intervals):\n",
    "    \"\"\"\n",
    "    Splits the video into chunks based on detected face intervals and further splits chunks longer than 3 seconds.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The ID of the video.\n",
    "        face_intervals (list): List of dictionaries with 'start' and 'end' times for each interval.\n",
    "\n",
    "    Returns:\n",
    "        list: List of paths to the created video chunks and sub-chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    try:\n",
    "        # Load the video\n",
    "        video = VideoFileClip(video_id + \".mp4\")\n",
    "\n",
    "        for i, seg in enumerate(face_intervals):\n",
    "            print(f\"Segment: {i}, Start: {seg['start']}, End: {seg['end']}\")\n",
    "            start = int(seg['start'])\n",
    "            end = math.ceil(seg['end'])\n",
    "            chunk = video.subclipped(start, end)\n",
    "            chunk_filename = f\"{video_id}__chunk__{i}.mp4\"\n",
    "            chunk.write_videofile(chunk_filename, codec=\"libx264\")\n",
    "            chunks.append(chunk_filename)\n",
    "\n",
    "            # Check if the chunk is longer than 3 seconds\n",
    "            if chunk.duration > 3:\n",
    "                print(f\"Chunk {chunk_filename} is longer than 3 seconds. Splitting into sub-chunks.\")\n",
    "                sub_chunks = []\n",
    "                for sub_start in range(0, int(chunk.duration), 3):\n",
    "                    sub_end = min(sub_start + 3, int(chunk.duration))\n",
    "                    sub_chunk = chunk.subclipped(sub_start, sub_end)\n",
    "                    sub_chunk_filename = chunk_filename.replace(f'__{i}', f'__{i}-{sub_start // 3}')\n",
    "                    sub_chunk.write_videofile(sub_chunk_filename, codec=\"libx264\")\n",
    "                    sub_chunks.append(sub_chunk_filename)\n",
    "\n",
    "                # Add sub-chunks to the list and remove the original chunk\n",
    "                chunks.remove(chunk_filename)\n",
    "                chunks.extend(sub_chunks)\n",
    "                os.remove(chunk_filename)  # Remove the original chunk file\n",
    "\n",
    "        video.close()\n",
    "        os.remove(video_id + \".mp4\")  # Remove the original video file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while chunking the video: {e}\")\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ea8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_chunk_names(path):\n",
    "    # extract video ID from the filename\n",
    "    video_id = path.split('__')[0]\n",
    "    chunk_name = path.split('__')[2].split('.')[0]\n",
    "    return video_id, chunk_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f30e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_video(video_file):\n",
    "    try:\n",
    "        # extract video ID from the filename\n",
    "        video_id, chunk_name = get_video_chunk_names(video_file)\n",
    "        print(f\"Video ID: {video_id}, Chunk Name: {chunk_name}\")\n",
    "\n",
    "        # import video\n",
    "        video_chunk = VideoFileClip(video_file)\n",
    "\n",
    "        # Split audio and video\n",
    "        audio_path = os.path.join(f\"{video_id}__audio__{chunk_name}.mp3\")\n",
    "        video_path = os.path.join(f\"{video_id}__video__{chunk_name}.mp4\")\n",
    "        print(f\"Audio path: {audio_path}, Video path: {video_path}\")\n",
    "\n",
    "\n",
    "        # Write audio to file\n",
    "        video_chunk.audio.write_audiofile(audio_path)\n",
    "\n",
    "        # Write video to file\n",
    "        video_only = video_chunk.without_audio()\n",
    "        video_only.write_videofile(video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "        #upload_to_s3(video_path, \"data/video\")\n",
    "\n",
    "        # Close the video clip\n",
    "        video_chunk.close()\n",
    "        video_only.close()\n",
    "\n",
    "        # delete chunk video file\n",
    "        os.remove(video_file)\n",
    "\n",
    "        print(\"Audio and video split successfully!\")\n",
    "        return audio_path, video_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c3a1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phoneme vocabulary (39 phonemes + blank, as per VALLR paper)\n",
    "phoneme_vocab = ['<blank>', 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', \n",
    "                 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', \n",
    "                 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n",
    "phoneme_to_index = {p: i for i, p in enumerate(phoneme_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4a4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text_phoneme(audio_file):\n",
    "    try:\n",
    "        # Use Whisper with English speech detection\n",
    "        result = pipe(\n",
    "            f\"{os.getcwd()}/{audio_file}\",\n",
    "            generate_kwargs={\"language\": \"en\", \"task\": \"transcribe\"}\n",
    "        )\n",
    "        text = result[\"text\"].strip()\n",
    "        video_id, chunk_name = get_video_chunk_names(audio_file)\n",
    "        \n",
    "        # Validate text\n",
    "        MAX_TEXT_LENGTH = 100  # ~10-20 words for 3 seconds\n",
    "        MIN_TEXT_LENGTH = 15   # Ensure meaningful transcription\n",
    "        if not text or len(text) < MIN_TEXT_LENGTH:\n",
    "            print(f\"Insufficient text length {len(text)} for {audio_file}: '{text}'\")\n",
    "            os.remove(audio_file)\n",
    "            return False, None\n",
    "        if len(text) > MAX_TEXT_LENGTH:\n",
    "            print(f\"Excessive text length {len(text)} for {audio_file}: '{text[:50]}...'\")\n",
    "            os.remove(audio_file)\n",
    "            return False, None\n",
    "        \n",
    "        print(f\"Transcription for {audio_file}: '{text}' (length: {len(text)})\")\n",
    "\n",
    "        phoneme_sequence = []\n",
    "        # Get phonemes for the word\n",
    "        for word in text.split():\n",
    "            phonemes = pronouncing.phones_for_word(word)\n",
    "            if phonemes:\n",
    "                # remove stress markers and split by spaces\n",
    "                phonemes = phonemes[0].split()\n",
    "                phonemes = [p.replace(\"0\", \"\").replace(\"1\", \"\").replace(\"2\", \"\") for p in phonemes]\n",
    "                phoneme_sequence.extend(phonemes)\n",
    "\n",
    "        phoneme_indices = [phoneme_to_index.get(p, 0) for p in phoneme_sequence]\n",
    "        \n",
    "        data = {\n",
    "            \"video_id\": video_id,\n",
    "            \"chunk_name\": chunk_name,\n",
    "            \"text\": text,\n",
    "            \"phonemes\": phoneme_sequence,\n",
    "            \"phoneme_indices\": phoneme_indices,\n",
    "\n",
    "        }\n",
    "        json_file = f\"{video_id}__text__{chunk_name}.json\"\n",
    "        with open(json_file, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(f\"Text saved to {json_file}\")\n",
    "\n",
    "        os.remove(audio_file)\n",
    "\n",
    "        return True, json_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {audio_file}: {e}\")\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cba7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face_video_and_save(video_path):\n",
    "    \"\"\"\n",
    "    Detects faces in a video, crops them, resizes to 224x224, and saves the frames to a .npz file.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        output_npz_path (str): Path to save the .npz file containing the cropped frames.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mp_face_detection = mp.solutions.face_detection\n",
    "        face_detection = mp_face_detection.FaceDetection()\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Detect faces in the frame\n",
    "            results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            if results.detections:\n",
    "                # Get the bounding box of the first detected face\n",
    "                bbox = results.detections[0].location_data.relative_bounding_box\n",
    "                h, w = frame.shape[:2]\n",
    "                x, y = int(bbox.xmin * w), int(bbox.ymin * h)\n",
    "                width, height = int(bbox.width * w), int(bbox.height * h)\n",
    "\n",
    "                # Crop and resize the face\n",
    "                face = frame[y:y+height, x:x+width]\n",
    "                face = cv2.resize(face, (224, 224))\n",
    "                frames.append(face)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Convert frames to a NumPy array and save to .npz\n",
    "        if frames:\n",
    "            frames_array = np.array(frames)\n",
    "            output_npz_path = video_path.replace('.mp4', '.npz').replace('video', 'face')\n",
    "            np.savez_compressed(output_npz_path, frames=frames_array)\n",
    "            print(f\"Frames saved to {output_npz_path}\")\n",
    "            upload_to_s3(output_npz_path, \"data/face\")\n",
    "            os.remove(output_npz_path)\n",
    "            os.remove(video_path)\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {e}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "395d13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.list_objects_v2(Bucket=bucket, Prefix=\"data/text/\")\n",
    "all_files = [obj[\"Key\"] for obj in response[\"Contents\"]]\n",
    "token = response.get(\"NextContinuationToken\")\n",
    "s3_items = True\n",
    "while s3_items:\n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket, Prefix=\"data/text/\", ContinuationToken=token)\n",
    "        if \"Contents\" in response:\n",
    "            all_files.extend([obj[\"Key\"] for obj in response[\"Contents\"]])\n",
    "            s3_items = response.get(\"IsTruncated\", False)\n",
    "            token = response.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            s3_items = False\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing S3 objects: {e}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfbf120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_files_and_check_video(video_id):\n",
    "    for file in all_files:\n",
    "        if video_id in file:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c3b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(youtube_url):\n",
    "    \"\"\"\n",
    "    Extracts the video ID from a YouTube URL.\n",
    "\n",
    "    Args:\n",
    "        youtube_url (str): The YouTube video URL.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted video ID, or None if the URL is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the URL contains 'v='\n",
    "        if \"v=\" in youtube_url:\n",
    "            video_id = youtube_url.split(\"v=\")[-1]\n",
    "            # Remove any additional parameters after the video ID\n",
    "            video_id = video_id.split(\"&\")[0]\n",
    "            return video_id\n",
    "        else:\n",
    "            print(f\"Invalid YouTube URL: {youtube_url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting video ID: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c3c8907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos after removing duplicates: 4769\n"
     ]
    }
   ],
   "source": [
    "playlist_url = 'https://www.youtube.com/playlist?list=PLOGi5-fAu8bEsgXDEOxRm73J8FRLtBfxU'\n",
    "video_urls = get_playlist_videos(playlist_url)\n",
    "\n",
    "# remove duplicate video urls\n",
    "all_video_urls = list(set(video_urls))\n",
    "print(f\"Total videos after removing duplicates: {len(all_video_urls)}\")\n",
    "\n",
    "# randomly shuffle the video urls\n",
    "random.shuffle(all_video_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c24d0766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos already processed: 31\n",
      "Percentage of videos already processed: 0.65%\n",
      "Number of videos chunks: 4214\n"
     ]
    }
   ],
   "source": [
    "num_processed = 0\n",
    "for youtube_url in all_video_urls:\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    is_processed = list_s3_files_and_check_video(video_id)\n",
    "    if is_processed: \n",
    "        num_processed += 1\n",
    "\n",
    "print(f\"Number of videos already processed: {num_processed}\")\n",
    "print(f\"Percentage of videos already processed: {num_processed / len(all_video_urls) * 100:.2f}%\")\n",
    "print(f\"Number of videos chunks: {len(all_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f32d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for youtube_url in all_video_urls:\n",
    "    try:\n",
    "        video_id = extract_video_id(youtube_url)\n",
    "        is_processed = list_s3_files_and_check_video(video_id)\n",
    "        if is_processed:\n",
    "            print(f\"Video {video_id} has already been processed. Skipping...\")\n",
    "            num_videos += 1\n",
    "            continue\n",
    "        video_id = download_youtube_video_yt_dlp(youtube_url)\n",
    "        face_intervals = detect_face_intervals(video_id)\n",
    "        chunks_list = chunk_video(video_id, face_intervals)\n",
    "        for chunk in chunks_list:\n",
    "            audio_path, video_path = split_audio_video(chunk)\n",
    "            crop_video, json_file = audio_to_text_phoneme(audio_path)\n",
    "            if crop_video:\n",
    "                remove_json = crop_face_video_and_save(video_path)\n",
    "                if remove_json:\n",
    "                    print(f\"Removing {json_file} due to no faces detected.\")\n",
    "                    os.remove(json_file)\n",
    "                else:\n",
    "                    print(f\"Uploading {json_file} to S3.\")\n",
    "                    upload_to_s3(json_file, \"data/text\")\n",
    "                    os.remove(json_file)\n",
    "            else:\n",
    "                print(f\"Skipping {chunk} due to transcription failure.\")\n",
    "                os.remove(video_path)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # remove any files that end in .mp4 \n",
    "    for file in os.listdir('.'):\n",
    "        if file.endswith('.mp4'):\n",
    "            os.remove(file)\n",
    "            print(f\"Removed {file}\")\n",
    "        if file.endswith('.json'):\n",
    "            os.remove(file)\n",
    "            print(f\"Removed {file}\")\n",
    "        if file.endswith('.npz'):\n",
    "            os.remove(file)\n",
    "            print(f\"Removed {file}\")\n",
    "        if file.endswith('.mp3'):\n",
    "            os.remove(file)\n",
    "            print(f\"Removed {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88374799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slip-ml-bXUTykFe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
