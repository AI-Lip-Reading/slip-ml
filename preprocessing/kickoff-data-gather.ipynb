{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2756cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "import pronouncing\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import json\n",
    "import boto3\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8edd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name = \"youtube\"\n",
    "region_name = \"us-east-1\"\n",
    "\n",
    "# Create a Secrets Manager client\n",
    "session = boto3.session.Session()\n",
    "secretsmanager = session.client(service_name='secretsmanager', region_name=region_name)\n",
    "\n",
    "get_secret_value_response = secretsmanager.get_secret_value(SecretId=secret_name)\n",
    "\n",
    "secret = get_secret_value_response['SecretString']\n",
    "api_key = json.loads(secret)[\"API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket = 'slip-ml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_videos(playlist_url):\n",
    "    \"\"\"\n",
    "    Extract all video URLs from a YouTube playlist using the YouTube Data API.\n",
    "    \n",
    "    Args:\n",
    "        playlist_url (str): The YouTube playlist URL (e.g., https://www.youtube.com/playlist?list=PL86SiVwkw_odmp-RVzD8yef3wU7Z2uD5a)\n",
    "        api_key (str): Your YouTube Data API key\n",
    "    \n",
    "    Returns:\n",
    "        list: List of video URLs\n",
    "    \"\"\"\n",
    "    # Extract playlist ID from URL\n",
    "    playlist_id = playlist_url.split(\"list=\")[-1].split(\"&\")[0]\n",
    "    \n",
    "    # Initialize YouTube API client\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    video_urls = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Request playlist items\n",
    "            request = youtube.playlistItems().list(\n",
    "                part=\"contentDetails\",\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,  # Max allowed per request\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            # Extract video IDs and create URLs\n",
    "            for item in response['items']:\n",
    "                video_id = item['contentDetails']['videoId']\n",
    "                video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "                video_urls.append(video_url)\n",
    "            \n",
    "            # Check for next page\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "    \n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851647e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_file_list(prefix):\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    all_files = [obj[\"Key\"] for obj in response[\"Contents\"]]\n",
    "    token = response.get(\"NextContinuationToken\")\n",
    "    s3_items = True\n",
    "    while s3_items:\n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=token)\n",
    "            if \"Contents\" in response:\n",
    "                all_files.extend([obj[\"Key\"] for obj in response[\"Contents\"]])\n",
    "                s3_items = response.get(\"IsTruncated\", False)\n",
    "                token = response.get(\"NextContinuationToken\")\n",
    "            else:\n",
    "                s3_items = False\n",
    "        except Exception as e:\n",
    "            print(f\"Error listing S3 objects: {e}\")\n",
    "            break\n",
    "\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef64b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_files_and_check_video(video_id, all_s3_files):\n",
    "    for file in all_s3_files:\n",
    "        if video_id in file:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(local_file, s3_folder):\n",
    "    s3_file = f\"{s3_folder}/{local_file}\"\n",
    "    try:\n",
    "        s3_client.upload_file(local_file, bucket, s3_file)\n",
    "        print(f\"Upload Successful: {local_file} -> {s3_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file was not found: {local_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return local_file, s3_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8258c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(youtube_url):\n",
    "    \"\"\"\n",
    "    Extracts the video ID from a YouTube URL.\n",
    "\n",
    "    Args:\n",
    "        youtube_url (str): The YouTube video URL.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted video ID, or None if the URL is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the URL contains 'v='\n",
    "        if \"v=\" in youtube_url:\n",
    "            video_id = youtube_url.split(\"v=\")[-1]\n",
    "            # Remove any additional parameters after the video ID\n",
    "            video_id = video_id.split(\"&\")[0]\n",
    "            return video_id\n",
    "        else:\n",
    "            print(f\"Invalid YouTube URL: {youtube_url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting video ID: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281452c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecs_client = boto3.client(\"ecs\", region_name=region_name)\n",
    "def kickoff_ecs_job(local_file, s3_folder):\n",
    "    \"\"\"\n",
    "    Kicks off an ECS job with a Docker container configured to process a YouTube video..\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure the container overrides to pass the video_id as a command argument\n",
    "    container_overrides = {\n",
    "        \"name\": 'vallr-gather-data',\n",
    "        #\"image\": '438465160412.dkr.ecr.us-east-1.amazonaws.com/vallr-gather-data',\n",
    "        \"command\": [\"python\", \"gather-data.py\", \"--s3-folder\", s3_folder, \"--local-file\", local_file],\n",
    "    }\n",
    "\n",
    "    # Run the ECS task\n",
    "    try:\n",
    "        response = ecs_client.run_task(\n",
    "            cluster='workspace',\n",
    "            taskDefinition='preprocess',\n",
    "            overrides={\"containerOverrides\": [container_overrides]},\n",
    "            launchType=\"FARGATE\",\n",
    "            networkConfiguration={\n",
    "                \"awsvpcConfiguration\": {\n",
    "                    \"subnets\": [\"subnet-02b0f97a6782f3791\"],  # Replace with your subnet IDs\n",
    "                    \"securityGroups\": [\"sg-07d656bd0202dad6b\"],  # Replace with your security group IDs\n",
    "                    \"assignPublicIp\": \"ENABLED\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while starting the ECS task: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video_yt_dlp(url):\n",
    "    # extract video ID from the URL\n",
    "    video_id = url.split(\"v=\")[-1]\n",
    "    if \"&\" in video_id:\n",
    "        video_id = video_id.split(\"&\")[0]\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": f\"{video_id}.%(ext)s\",  # Output path and filename\n",
    "        \"format\": \"best\",  # Select the best single file (video + audio)\n",
    "        \"merge_output_format\": None,  # Avoid merging, stick to single stream\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(\"Download completed successfully!\")\n",
    "        local_file, s3_folder = upload_to_s3(video_id + '.mp4', 'data/ted')\n",
    "        os.remove(f\"{video_id}.mp4\")\n",
    "        return local_file, s3_folder\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aee24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_s3_files = []\n",
    "for p in ['data/vallr/train/face/', 'data/vallr/test/face/']:\n",
    "    all_s3_files.extend(create_s3_file_list(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_url = 'https://www.youtube.com/playlist?list=PLOGi5-fAu8bEsgXDEOxRm73J8FRLtBfxU'\n",
    "video_urls = get_playlist_videos(playlist_url)\n",
    "\n",
    "# remove duplicate video urls\n",
    "all_video_urls = list(set(video_urls))\n",
    "print(f\"Total videos after removing duplicates: {len(all_video_urls)}\")\n",
    "\n",
    "# randomly shuffle the video urls\n",
    "random.shuffle(all_video_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processed = 0\n",
    "to_be_processed = []\n",
    "for youtube_url in all_video_urls:\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    is_processed = list_s3_files_and_check_video(video_id, all_s3_files)\n",
    "    if is_processed: \n",
    "        num_processed += 1\n",
    "    else:\n",
    "        to_be_processed.append(youtube_url)\n",
    "        \n",
    "\n",
    "print(f\"Number of videos already processed: {num_processed}\")\n",
    "print(f\"Percentage of videos already processed: {num_processed / len(all_video_urls) * 100:.2f}%\")\n",
    "print(f\"Number of videos chunks: {len(all_s3_files)}\")\n",
    "print(f\"Number of videos to be processed: {len(to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61af058",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_tasks = []\n",
    "for youtube_url in to_be_processed:\n",
    "    if len(running_tasks) <= 17:\n",
    "            try:\n",
    "                print(f\"Processing video: {youtube_url}\")\n",
    "                local_file, s3_folder = download_youtube_video_yt_dlp(youtube_url)\n",
    "                response = kickoff_ecs_job(local_file, s3_folder)\n",
    "                task_arn = response['tasks'][0]['taskArn']\n",
    "                running_tasks.append(task_arn)\n",
    "            except:\n",
    "                 print(f\"Wait for the task to finish before starting a new one.\")\n",
    "                 time.sleep(60*10)\n",
    "    else:\n",
    "        for task_arn in running_tasks:\n",
    "            try:\n",
    "                describe = ecs_client.describe_tasks(\n",
    "                        cluster='workspace',\n",
    "                        tasks=[task_arn],\n",
    "                )\n",
    "                task_arn = describe['tasks'][0]['taskArn']\n",
    "                status = describe['tasks'][0]['lastStatus']\n",
    "                if status == 'STOPPED':\n",
    "                    running_tasks.remove(task_arn)\n",
    "                    print(f\"Task {task_arn} has stopped.\")\n",
    "                else:\n",
    "                    print(f\"Task {task_arn} is still running.\")\n",
    "                    print(f\"Wait for the task to finish before starting a new one.\")\n",
    "                    time.sleep(60*10)\n",
    "            except IndexError:\n",
    "                print(f\"Task {task_arn} not found.\")\n",
    "                running_tasks.remove(task_arn)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while describing the task: {e}\")\n",
    "                time.sleep(60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28b5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slip-ml-bXUTykFe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
