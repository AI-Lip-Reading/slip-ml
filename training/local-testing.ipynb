{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "439dbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import torch\n",
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from source.lipnet import LipNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c15b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download the model from S3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'slip-ml'\n",
    "model_key = 'models/pytorch-training-2025-05-09-14-46-05-805/output/model.tar.gz'\n",
    "local_model_path = 'model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e47ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, model_key, local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb8ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model file\n",
    "with tarfile.open(local_model_path, 'r:gz') as tar:\n",
    "    tar.extractall(path='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f97491a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated feature map size: 1728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LipNet(\n",
       "  (conv1): Conv3d(3, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (conv2): Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2))\n",
       "  (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (conv3): Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (gru1): GRU(1728, 256, batch_first=True, bidirectional=True)\n",
       "  (gru2): GRU(512, 256, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the model\n",
    "model_path = 'model/model.pth'  # Replace with the actual path of the model file\n",
    "model = LipNet(img_c=3, img_w=100, img_h=50, frames_n=90)\n",
    "state_dict = torch.load(model_path)\n",
    "# Remove \"module.module.\" prefix from keys if present\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    new_key = key.replace(\"module.module.\", \"\")  # Remove the prefix\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "# Load the modified state_dict into the model\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4b71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download test data from S3\n",
    "test_data_key = 'data/preprocessing-2/test/videos/_xTCtX0E8H4__numpy__0.npz'\n",
    "local_test_data_path = 'test_data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7854126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, test_data_key, local_test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac9a92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(local_test_data_path, allow_pickle=True) as data:\n",
    "    # Assuming the key for frames in the .npz file is 'frames'\n",
    "    frames = data['frames'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b2ebde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frames before permute: (90, 50, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of frames before permute:\", frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be299551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the permute operation based on the shape\n",
    "if len(frames.shape) == 4:  # Expected shape (T, H, W, C)\n",
    "    frames = torch.tensor(frames, dtype=torch.float32).permute(3, 0, 1, 2)  # (C, T, H, W)\n",
    "elif len(frames.shape) == 3:  # Handle case where channel dimension is missing\n",
    "    frames = torch.tensor(frames, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected shape for frames: {frames.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c49ada93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frames after permute: torch.Size([3, 90, 50, 100])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of frames after permute:\", frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "740b2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frames = frames.unsqueeze(0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11da503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conv layers - Channels: 96, Height: 3, Width: 6\n",
      "Inference results: tensor([[[-1.1817, -2.9836, -4.4086,  ..., -7.1071, -6.4708, -6.2199],\n",
      "         [-0.7410, -3.1898, -4.8516,  ..., -7.0610, -6.8473, -6.7695],\n",
      "         [-0.5099, -3.4486, -5.1885,  ..., -6.9988, -7.0927, -7.1037],\n",
      "         ...,\n",
      "         [-0.8665, -3.5289, -4.7868,  ..., -2.6968, -4.6994, -5.2443],\n",
      "         [-1.3458, -3.7186, -4.7751,  ..., -1.4195, -3.9312, -4.5409],\n",
      "         [-2.4514, -4.4250, -5.1537,  ..., -0.5200, -3.4915, -4.2173]]])\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Run inference\n",
    "with torch.no_grad():\n",
    "    results = model(test_frames)\n",
    "print(\"Inference results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35ebf493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: .\n"
     ]
    }
   ],
   "source": [
    "def decode_ctc(predictions, idx_to_char, blank=0):\n",
    "    \"\"\"\n",
    "    Decode CTC output using greedy decoding.\n",
    "\n",
    "    Args:\n",
    "        predictions (torch.Tensor): Model output of shape (batch_size, T, num_classes).\n",
    "        idx_to_char (dict): Mapping from character indices to characters.\n",
    "        blank (int): Index of the blank token.\n",
    "\n",
    "    Returns:\n",
    "        list: Decoded text for each sample in the batch.\n",
    "    \"\"\"\n",
    "    decoded_texts = []\n",
    "    for pred in predictions:\n",
    "        decoded_sequence = []\n",
    "        prev_token = None\n",
    "        for token_idx in pred:\n",
    "            if token_idx != blank and token_idx != prev_token:  # Remove blanks and duplicates\n",
    "                decoded_sequence.append(idx_to_char[token_idx.item()])\n",
    "            prev_token = token_idx\n",
    "        decoded_texts.append(\"\".join(decoded_sequence))\n",
    "    return decoded_texts\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `results` is the output of the model with shape (batch_size, T, num_classes)\n",
    "# and `idx_to_char` is a dictionary mapping indices to characters.\n",
    "idx_to_char = {0: \" \", 1: \"a\", 2: \"b\", 3: \"c\", 4: \"d\", 5: \"e\", 6: \"f\", 7: \"g\", 8: \"h\", 9: \"i\", 10: \"j\", 11: \"k\", 12: \"l\", 13: \"m\", 14: \"n\", 15: \"o\", 16: \"p\", 17: \"q\", 18: \"r\", 19: \"s\", 20: \"t\", 21: \"u\", 22: \"v\", 23: \"w\", 24: \"x\", 25: \"y\", 26: \"z\", 27: \"'\", 28: \".\", 29: \"?\", 30: \"!\"}  # Example mapping\n",
    "\n",
    "# Get the most likely character indices\n",
    "predicted_indices = torch.argmax(results, dim=-1)  # Shape: (batch_size, T)\n",
    "\n",
    "# Decode predictions\n",
    "decoded_texts = decode_ctc(predicted_indices, idx_to_char)\n",
    "\n",
    "# Print the decoded texts\n",
    "for i, text in enumerate(decoded_texts):\n",
    "    print(f\"Sample {i + 1}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a6ff810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 28]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50efb55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: tensor([ 9, 20, 27, 19,  0, 20, 15, 15,  0, 19, 12, 15, 23,  0,  9, 20, 27, 19,\n",
      "         0, 20, 15, 15,  0, 19, 12, 15, 23, 28])\n",
      "One-hot encoded labels shape: torch.Size([28, 32])\n",
      "One-hot encoded labels:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example input: 1D tensor of labels\n",
    "labels = torch.tensor([9, 20, 27, 19, 0, 20, 15, 15, 0, 19, 12, 15, 23, 0, 9, 20, 27, 19, 0, 20, 15, 15, 0, 19, 12, 15, 23, 28])\n",
    "\n",
    "# Number of classes (e.g., 32 for indices 0-31)\n",
    "num_classes = 32\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = F.one_hot(labels, num_classes=num_classes)\n",
    "\n",
    "# Convert to float tensor if needed (e.g., for compatibility with loss functions)\n",
    "one_hot_labels = one_hot_labels.float()\n",
    "\n",
    "print(\"Original labels:\", labels)\n",
    "print(\"One-hot encoded labels shape:\", one_hot_labels.shape)\n",
    "print(\"One-hot encoded labels:\\n\", one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12895e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slip-ml-bXUTykFe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
